{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC413_Project_StackerModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwRtdtWyn2Z"
      },
      "source": [
        "# Written by Jay Jaewon Yoo (UofT Student Number 1002939671)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnGQrfLc9WqA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTNxn3jD9cKF"
      },
      "source": [
        "class stacker_dataset(Dataset):\n",
        "    def __init__(self, data_to_stack, labels):\n",
        "        super().__init__()\n",
        "        # elements of data_to_stack are all (dataset size, m, n) where images are m x n\n",
        "\n",
        "        self.num_data = len(data_to_stack[0])\n",
        "        self.train_data = torch.cat([torch.unsqueeze(data, dim=1) for data in data_to_stack], dim=1)\n",
        "            # dataset size x N x m x n where N is the number of inputs to stack\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.train_data[idx], self.labels[idx]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QlfKrwUEUNx"
      },
      "source": [
        "def stacker_layer(in_channels, out_channels, kernel_size=3, stride=1, \\\n",
        "                  padding=1, bias=True, batchnorm=True, activation='relu'):\n",
        "    # Convolution layer that maintains shape \n",
        "        # with optional activation layer and batchnorm\n",
        "    # Use stride = 1, kernel = 3, padding = 1 for convenience\n",
        "    # Activation argument is one of 'relu', 'sigmoid', or 'none\n",
        "\n",
        "    layers = []\n",
        "    # Adding convolutional layer\n",
        "    layers.append(nn.Conv2d(in_channels=in_channels, \\\n",
        "                            out_channels=out_channels, \\\n",
        "                            kernel_size=kernel_size, \\\n",
        "                            stride=stride, \\\n",
        "                            padding=padding, \\\n",
        "                            bias=bias))\n",
        "\n",
        "    # Adding batchnorm\n",
        "    if batchnorm:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    # Adding activation\n",
        "    if activation == 'relu':\n",
        "        layers.append(nn.ReLU())\n",
        "    elif activation == 'sigmoid':\n",
        "        layers.append(nn.Sigmoid())\n",
        "    elif activation == 'none':\n",
        "        pass\n",
        "    else:\n",
        "        assert False, \"Invalid activation function.\"\n",
        "        \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def check_power_2(val):\n",
        "    # Checks if input val is a power of 2\n",
        "\n",
        "    return (val & (val - 1) == 0) and val != 0\n",
        "\n",
        "class stacker(nn.Module):\n",
        "    def __init__(self, num_input_types, initial_channels=64, encode_channels=16):\n",
        "        # initial_channels is the initial channels to convolve to\n",
        "        # encode channels is the number of channels to decode to\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        assert check_power_2(initial_channels) and \\\n",
        "        check_power_2(encode_channels), \\\n",
        "        \"initial_channels and encode_channels must be powers of 2.\"\n",
        "\n",
        "        num_encode_decode_layers = np.log2(initial_channels // encode_channels).astype(int)\n",
        "        \n",
        "        self.net = []\n",
        "\n",
        "        # First layer\n",
        "        self.net.append(stacker_layer(in_channels=num_input_types, \\\n",
        "                                      out_channels=initial_channels, \\\n",
        "                                      activation='relu', \\\n",
        "                                      batchnorm=True))\n",
        "\n",
        "        # Encoding\n",
        "        for layer_idx in range(0, num_encode_decode_layers):\n",
        "            self.net.append(stacker_layer(in_channels=initial_channels // (2 ** layer_idx), \\\n",
        "                                          out_channels=initial_channels // (2 ** (layer_idx + 1)), \\\n",
        "                                          activation='relu', \\\n",
        "                                          batchnorm=True))\n",
        "        \n",
        "        # Decoding\n",
        "        # Note that no batchnorm in the final decoding layer\n",
        "        for layer_idx in range(0, num_encode_decode_layers):\n",
        "            self.net.append(stacker_layer(in_channels=encode_channels * (2 ** layer_idx), \\\n",
        "                                          out_channels=encode_channels * (2 ** (layer_idx + 1)), \\\n",
        "                                          activation='relu', \\\n",
        "                                          batchnorm=layer_idx != num_encode_decode_layers - 1))\n",
        "\n",
        "        # Final layer\n",
        "        self.net.append(stacker_layer(in_channels=initial_channels, \\\n",
        "                                      out_channels=1, \\\n",
        "                                      activation='sigmoid', \\\n",
        "                                      batchnorm=False))\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "    \n",
        "    def forward(self, concatenated_inputs):\n",
        "        output = self.net(concatenated_inputs)\n",
        "        return output.squeeze()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehVy0uSrV73"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 2\n",
        "num_epochs = 20\n",
        "learning_rate = 1e-4\n",
        "summary_epoch_interval = 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W0izdJKq5Iv"
      },
      "source": [
        "# Testing with 5 input types using images of 300x350\n",
        "dummy_data = [torch.rand(50, 300, 350) for idx in range(5)] # Change\n",
        "dummy_labels = torch.rand(50, 300, 350) # Change\n",
        "\n",
        "# Preparing dataloader\n",
        "num_input_types = len(dummy_data)\n",
        "dataset = stacker_dataset(dummy_data, dummy_labels)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=True, num_workers=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmMu1JjQrtN0",
        "outputId": "5e980224-5d52-452c-cb55-cfae8203fe0e"
      },
      "source": [
        "stacker_model = stacker(num_input_types=num_input_types)\n",
        "stacker_model.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stacker(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQvZgwUbsFEn",
        "outputId": "0605ee09-89e8-4840-b4f4-4813cdb492bf"
      },
      "source": [
        "optimizer = torch.optim.Adam(lr=learning_rate, params=stacker_model.parameters())\n",
        "mse_loss_function = nn.MSELoss()\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    cumulated_loss = 0\n",
        "\n",
        "    for model_input, labels in dataloader:\n",
        "        model_input = model_input.cuda()\n",
        "        labels = labels.cuda()\n",
        "        model_output = stacker_model(model_input)\n",
        "        loss = torch.sqrt(mse_loss_function(model_output, labels))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cumulated_loss += loss.item()\n",
        "        \n",
        "    if not epoch % summary_epoch_interval:\n",
        "        print(\"Epoch %d, Total loss %0.6f\" % (epoch, cumulated_loss))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Total loss 7.218555\n",
            "Epoch 20, Total loss 7.212712\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}