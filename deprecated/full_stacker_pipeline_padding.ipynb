{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_stacker_pipeline_padding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_G8aermNnoC"
      },
      "source": [
        "# Algorithmic methods imports\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage, misc\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BQQQybIZIwG"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from IPython.display import clear_output "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg1WvW0KOFwj"
      },
      "source": [
        "data_path = \"./drive/MyDrive/CSC413 Project/trainA\"\n",
        "label_path = \"./drive/MyDrive/CSC413 Project/trainB\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAZenmvaULBG"
      },
      "source": [
        "# Defining algorithmic processing methods\n",
        "Written by Kevin Zhang"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1y2qC3sT4zq"
      },
      "source": [
        "########################################################\n",
        "# PART 1 - Median Filtering\n",
        "########################################################\n",
        "def median_filter(image_path):\n",
        "  img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # Load image\n",
        "  img_median = cv2.medianBlur(img, 25) # Add median filter to image\n",
        "  result = np.minimum(img.astype(np.uint16)+(255-img_median.astype(np.uint16)), 255)\n",
        "  return result.astype(np.uint8)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSEalB-aUGjg"
      },
      "source": [
        "########################################################\n",
        "# PART 2 - Edge Detection, Dilation Erosion\n",
        "########################################################\n",
        "def edge_dilation_erosion_filter(image_path):\n",
        "  img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # Load image\n",
        "  edges = cv2.Canny(img,100,200)\n",
        "  dilated = cv2.dilate(edges, np.ones((3,3),np.uint8), iterations=1)\n",
        "  eroded = cv2.erode(dilated, np.ones((4,4),np.uint8), iterations=1)\n",
        "  return cv2.bitwise_not(eroded)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0JF0WqEUHlV"
      },
      "source": [
        "########################################################\n",
        "# PART 3 - Adaptive Filter\n",
        "########################################################\n",
        "def adaptive_filter(image_path):\n",
        "  img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # Load image\n",
        "  return cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
        "            cv2.THRESH_BINARY,15,20)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdh8BsTwWPAO"
      },
      "source": [
        "## Creating images using algorithmic methods\n",
        "\n",
        "Written by Kevin Zhang"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CjFQxmSUSUp"
      },
      "source": [
        "if not os.path.exists(data_path+\"/median_filtered\"):\n",
        "  os.mkdir(data_path+\"/median_filtered\")\n",
        "if not os.path.exists(data_path+\"/edge_dilation_erosion\"):\n",
        "  os.mkdir(data_path+\"/edge_dilation_erosion\")\n",
        "if not os.path.exists(data_path+\"/adaptive_filtered\"):\n",
        "  os.mkdir(data_path+\"/adaptive_filtered\")\n",
        "\n",
        "for img in sorted(os.listdir(data_path)):\n",
        "  if img.endswith('.png'):\n",
        "    input_image_path = os.path.join(data_path,img)\n",
        "\n",
        "    median_filter_path = os.path.join(data_path+\"/median_filtered\",img)\n",
        "    edge_dilation_erosion_path = os.path.join(data_path+\"/edge_dilation_erosion\",img)\n",
        "    adaptive_filter_path = os.path.join(data_path+\"/adaptive_filtered\",img)\n",
        "\n",
        "    if not os.path.exists(adaptive_filter_path):\n",
        "      cv2.imwrite(median_filter_path, median_filter(input_image_path))\n",
        "    if not os.path.exists(edge_dilation_erosion_path):\n",
        "      cv2.imwrite(edge_dilation_erosion_path, edge_dilation_erosion_filter(input_image_path))\n",
        "    if not os.path.exists(adaptive_filter_path):\n",
        "      cv2.imwrite(adaptive_filter_path, adaptive_filter(input_image_path))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "KhmLrIffUxhn",
        "outputId": "bdeefd89-4568-42a1-a1d6-ca076772e668"
      },
      "source": [
        "# Test image\n",
        "result = edge_dilation_erosion_filter(os.path.join(data_path, \"img_0000.png\"))\n",
        "cv2_imshow(result)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=540x420 at 0x7F27BF8DB910>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uezuBRZ_aaKf"
      },
      "source": [
        "# Machine Learning Methods\n",
        "Written by Jay Yoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmBZaIDliPay"
      },
      "source": [
        "def prepare_params(batch_size=128, num_epochs=100, learning_rate=1e-4, \\\n",
        "                   summary_epoch_interval=10, loss_function=nn.MSELoss(), \\\n",
        "                   optimizer=torch.optim.Adam):\n",
        "  # optimizer is passed the function definition, not a called function \n",
        "    # (note the lack of brackets in the base argument)\n",
        "  \n",
        "  params = {\n",
        "      'batch_size' : batch_size,\n",
        "      'num_epochs' : num_epochs,\n",
        "      'learning_rate' : learning_rate,\n",
        "      'summary_epoch_interval' : summary_epoch_interval, \n",
        "      'loss_function' : loss_function, \n",
        "      'optimizer' : optimizer,\n",
        "  }\n",
        "\n",
        "  return params"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3TLQU9wdX5x"
      },
      "source": [
        "class model_container():\n",
        "  def __init__(self, dataset, model, params):\n",
        "    # Model does not have to be transferred to cuda gpu\n",
        "\n",
        "    self.batch_size = params['batch_size']\n",
        "    self.num_epochs = params['num_epochs']\n",
        "    self.learning_rate = params['learning_rate']\n",
        "    self.summary_epoch_interval = params['summary_epoch_interval']\n",
        "    self.loss_function = params['loss_function']\n",
        "    self.optimizer = params['optimizer']\n",
        "\n",
        "    self.dataloader = DataLoader(dataset, batch_size=self.batch_size, pin_memory=True, num_workers=0)\n",
        "    self.model = model.cuda()\n",
        "\n",
        "  def train(self):\n",
        "    self.model.train()\n",
        "\n",
        "    # optimizer = torch.optim.Adam(lr=learning_rate, params=self.model.parameters())\n",
        "    optimizer = self.optimizer(lr=self.learning_rate, params=self.model.parameters())\n",
        "\n",
        "    for epoch in range(1, self.num_epochs + 1):\n",
        "        cumulated_loss = 0\n",
        "\n",
        "        for model_input, labels in self.dataloader:\n",
        "            model_input = model_input.cuda()\n",
        "            labels = labels.cuda()\n",
        "            model_output = self.model(model_input)\n",
        "            loss = self.loss_function(model_output, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            cumulated_loss += loss.item()\n",
        "            \n",
        "        if not epoch % self.summary_epoch_interval:\n",
        "            print(\"Epoch %d, Total loss %0.6f\" % (epoch, cumulated_loss))\n",
        "\n",
        "  def inference(self, data_to_infer, dataset_shapes, save_path=None, filenames=None):\n",
        "    # Assumed to be list of numpy\n",
        "    # Add option to automatically save to a directory if memory is a concern\n",
        "\n",
        "    self.model.eval()\n",
        "\n",
        "    if save_path is None:\n",
        "      outputs = []\n",
        "      for data in data_to_infer:\n",
        "        model_input = torch.from_numpy(data)\n",
        "        model_input = model_input.type(torch.FloatTensor)\n",
        "        model_input = model_input.cuda()\n",
        "        outputs.append(self.model(model_input).cpu().detach().numpy())\n",
        "\n",
        "      return outputs\n",
        "    else:\n",
        "      if filenames is None:\n",
        "        filenames = [str(idx) for idx in range(len(data_to_infer))]\n",
        "      for idx, data in enumerate(data_to_infer):\n",
        "        model_input = torch.from_numpy(data)\n",
        "        model_input = model_input.type(torch.FloatTensor)\n",
        "        model_input = model_input.cuda()\n",
        "        model_output = self.model(model_input).cpu().detach().numpy()\n",
        "\n",
        "        cv2.imwrite(os.path.join(save_path, filenames[idx]) + '.png', model_output)\n",
        "\n",
        "  def delete_data(self):\n",
        "    # For memory optimizations\n",
        "    del self.dataloader\n",
        "  \n",
        "  def get_model():\n",
        "    self.model.eval()\n",
        "    return self.model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3KVHj9maO0V"
      },
      "source": [
        "##  Autoencoder model\n",
        "Written by Jay Yoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iosiXxWcYHV6"
      },
      "source": [
        "class autoencoder_dataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        super().__init__()\n",
        "        # data and labels are both (dataset size, m, n) where images are m x n\n",
        "\n",
        "        self.num_data = len(data)\n",
        "        self.train_data = torch.unsqueeze(torch.from_numpy(data), dim=1)\n",
        "        self.train_data = self.train_data.type(torch.FloatTensor)\n",
        "        self.labels = torch.from_numpy(labels)\n",
        "        self.labels = self.labels.type(torch.FloatTensor)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.train_data[idx], self.labels[idx]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgkdASRxXkAw"
      },
      "source": [
        "def autoencoder_layer(in_channels, out_channels, kernel_size=3, stride=1, \\\n",
        "                  padding=1, bias=True, batchnorm=True, activation='relu', \\\n",
        "                  upsample=None):\n",
        "    # Convolution layer that maintains shape \n",
        "        # with optional activation layer and batchnorm\n",
        "    # Use stride = 1, kernel = 3, padding = 1 for convenience\n",
        "    # Activation argument is one of 'relu', 'sigmoid', 'leaky_relu', or 'none\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    # Upsampling\n",
        "    if upsample is not None:\n",
        "        layers.append(nn.Upsample(scale_factor=upsample))\n",
        "\n",
        "    # Adding convolutional layer\n",
        "    layers.append(nn.Conv2d(in_channels=in_channels, \\\n",
        "                            out_channels=out_channels, \\\n",
        "                            kernel_size=kernel_size, \\\n",
        "                            stride=stride, \\\n",
        "                            padding=padding, \\\n",
        "                            bias=bias))\n",
        "\n",
        "    # Adding batchnorm\n",
        "    if batchnorm:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    # Adding activation\n",
        "    if activation == 'relu':\n",
        "        layers.append(nn.ReLU())\n",
        "    elif activation == 'sigmoid':\n",
        "        layers.append(nn.Sigmoid())\n",
        "    elif activation == 'leaky_relu':\n",
        "        layers.append(nn.LeakyReLU())\n",
        "    elif activation == 'none':\n",
        "        pass\n",
        "    else:\n",
        "        assert False, \"Invalid activation function.\"\n",
        "        \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self, num_hidden_channels=64):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.net = []\n",
        "\n",
        "        self.net.append(autoencoder_layer(in_channels=1, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=True, \\\n",
        "                                      upsample=None))\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=False, \\\n",
        "                                      upsample=None))\n",
        "        self.net.append(nn.MaxPool2d(2)) # Pool to half of shape\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=True, \\\n",
        "                                      upsample=None))\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=False, \\\n",
        "                                      upsample=2))\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=1, \\\n",
        "                                      activation='sigmoid', \\\n",
        "                                      batchnorm=False, \\\n",
        "                                      upsample=None))\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "    \n",
        "    def forward(self, concatenated_inputs):\n",
        "        output = self.net(concatenated_inputs)\n",
        "        return output.squeeze()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftcCNfmalbX8"
      },
      "source": [
        "def get_images_from_dir(data_path, track_progress=True, stop_idx=None, \\\n",
        "                        dataset_shapes=None):\n",
        "\n",
        "  dir_paths = os.listdir(data_path)\n",
        "  num_paths = len(dir_paths)\n",
        "\n",
        "  if stop_idx is None:\n",
        "    stop_idx = num_paths\n",
        "\n",
        "  if track_progress == True:\n",
        "    def show_progress(idx):\n",
        "      clear_output()\n",
        "      print(idx, '/', stop_idx)\n",
        "  else:\n",
        "    def show_progress(idx):\n",
        "      pass\n",
        "\n",
        "  if dataset_shapes is None:\n",
        "    png_idx = 0\n",
        "    dataset_shapes = []\n",
        "    for idx, img in enumerate(sorted(dir_paths)):\n",
        "      if png_idx == stop_idx:\n",
        "        break\n",
        "        \n",
        "      show_progress(png_idx)\n",
        "      if img.endswith('.png'):\n",
        "        image_path = os.path.join(data_path,img)\n",
        "        raw_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        dataset_shapes.append(raw_image.shape)\n",
        "        png_idx += 1\n",
        "\n",
        "  num_pngs = len(dataset_shapes)\n",
        "  image_shape = [None, None]\n",
        "  for shape_idx in range(2):\n",
        "    image_shape[shape_idx] = max([shape[shape_idx] for shape in dataset_shapes])\n",
        "  images = np.zeros([num_pngs] + image_shape)\n",
        "\n",
        "  png_idx = 0\n",
        "  for idx, img in enumerate(sorted(dir_paths)):\n",
        "    if png_idx == stop_idx:\n",
        "      break\n",
        "\n",
        "    show_progress(idx)\n",
        "    if img.endswith('.png'):\n",
        "      image_path = os.path.join(data_path,img)\n",
        "      raw_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "      diff_y = (image_shape[0] - raw_image.shape[0]) // 2\n",
        "      diff_x = (image_shape[1] - raw_image.shape[1]) // 2\n",
        "      images[png_idx, \\\n",
        "             diff_y:image_shape[0] - diff_y, \\\n",
        "             diff_x:image_shape[1] - diff_x] = raw_image\n",
        "      png_idx += 1\n",
        "\n",
        "  return images, dataset_shapes"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "lHo04LxhmI7G",
        "outputId": "1fed99ed-b4dd-4f32-9423-98c246caa5d3"
      },
      "source": [
        "autoencoder_train_data, dataset_shapes = get_images_from_dir(data_path, stop_idx=500)\n",
        "autoencoder_labels, dataset_shapes = get_images_from_dir(label_path, dataset_shapes=dataset_shapes, stop_idx=500)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1348 / 2448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-faa8c9f7659e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mautoencoder_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_from_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mautoencoder_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_from_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-a37bc73bce9e>\u001b[0m in \u001b[0;36mget_images_from_dir\u001b[0;34m(data_path, track_progress, stop_idx, dataset_shapes)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0mraw_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m       \u001b[0mdiff_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mraw_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mdiff_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mraw_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQo3Xyq9jasN"
      },
      "source": [
        "dataset = autoencoder_dataset(autoencoder_train_data, autoencoder_labels)\n",
        "autoencoder_model = autoencoder(num_hidden_channels=32)\n",
        "autoencoder_params = prepare_params(batch_size=16, summary_epoch_interval=1, num_epochs=5, learning_rate=1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XhLuUHCTCm8"
      },
      "source": [
        "del autoencoder_train_data\n",
        "del autoencoder_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT5jMCW3jwRu"
      },
      "source": [
        "autoencoder = model_container(dataset, autoencoder_model, autoencoder_params, dataset_shapes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2gqFlRfkX-u"
      },
      "source": [
        "autoencoder.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6I1jZ10RgiP"
      },
      "source": [
        "# Just for testing code, have to change to get actual test data\n",
        "\n",
        "autoencoder.delete_data()\n",
        "autoencoder_train_data, dataset_shapes = get_images_from_dir(data_path, stop_idx=50, dataset_shapes=dataset_shapes)\n",
        "autoencoder.inference()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}