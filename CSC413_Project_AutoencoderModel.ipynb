{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC413_Project_AutoencoderModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwRtdtWyn2Z"
      },
      "source": [
        "# Written by Jay Jaewon Yoo (UofT Student Number 1002939671)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnGQrfLc9WqA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTNxn3jD9cKF"
      },
      "source": [
        "class autoencoder_dataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        super().__init__()\n",
        "        # data and labels are both (dataset size, m, n) where images are m x n\n",
        "\n",
        "        self.num_data = len(data)\n",
        "        self.train_data = torch.unsqueeze(data, dim=1)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.train_data[idx], self.labels[idx]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QlfKrwUEUNx"
      },
      "source": [
        "def autoencoder_layer(in_channels, out_channels, kernel_size=3, stride=1, \\\n",
        "                  padding=1, bias=True, batchnorm=True, activation='relu', \\\n",
        "                  upsample=None):\n",
        "    # Convolution layer that maintains shape \n",
        "        # with optional activation layer and batchnorm\n",
        "    # Use stride = 1, kernel = 3, padding = 1 for convenience\n",
        "    # Activation argument is one of 'relu', 'sigmoid', 'leaky_relu', or 'none\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    # Upsampling\n",
        "    if upsample is not None:\n",
        "        layers.append(nn.Upsample(scale_factor=upsample))\n",
        "\n",
        "    # Adding convolutional layer\n",
        "    layers.append(nn.Conv2d(in_channels=in_channels, \\\n",
        "                            out_channels=out_channels, \\\n",
        "                            kernel_size=kernel_size, \\\n",
        "                            stride=stride, \\\n",
        "                            padding=padding, \\\n",
        "                            bias=bias))\n",
        "\n",
        "    # Adding batchnorm\n",
        "    if batchnorm:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    # Adding activation\n",
        "    if activation == 'relu':\n",
        "        layers.append(nn.ReLU())\n",
        "    elif activation == 'sigmoid':\n",
        "        layers.append(nn.Sigmoid())\n",
        "    elif activation == 'leaky_relu':\n",
        "        layers.append(nn.LeakyReLU())\n",
        "    elif activation == 'none':\n",
        "        pass\n",
        "    else:\n",
        "        assert False, \"Invalid activation function.\"\n",
        "        \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self, num_hidden_channels=64):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.net = []\n",
        "\n",
        "        self.net.append(autoencoder_layer(in_channels=1, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=True, \\\n",
        "                                      upsample=None))\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=False, \\\n",
        "                                      upsample=None))\n",
        "        self.net.append(nn.MaxPool2d(2)) # Pool to half of shape\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=True, \\\n",
        "                                      upsample=None))\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=num_hidden_channels, \\\n",
        "                                      activation='leaky_relu', \\\n",
        "                                      batchnorm=False, \\\n",
        "                                      upsample=2))\n",
        "        self.net.append(autoencoder_layer(in_channels=num_hidden_channels, \\\n",
        "                                      out_channels=1, \\\n",
        "                                      activation='sigmoid', \\\n",
        "                                      batchnorm=False, \\\n",
        "                                      upsample=None))\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "    \n",
        "    def forward(self, concatenated_inputs):\n",
        "        output = self.net(concatenated_inputs)\n",
        "        return output.squeeze()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehVy0uSrV73"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 2\n",
        "num_epochs = 20\n",
        "learning_rate = 1e-4\n",
        "summary_epoch_interval = 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W0izdJKq5Iv"
      },
      "source": [
        "# Testing with 5 input types using images of 300x350\n",
        "dummy_data = torch.rand(50, 300, 350) # Change\n",
        "dummy_labels = torch.rand(50, 300, 350) # Change\n",
        "\n",
        "# Preparing dataloader\n",
        "num_input_types = len(dummy_data)\n",
        "dataset = autoencoder_dataset(dummy_data, dummy_labels)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=True, num_workers=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmMu1JjQrtN0",
        "outputId": "66fb3330-5dac-47fc-d4a3-564e0bba2d14"
      },
      "source": [
        "autoencoder_model = autoencoder()\n",
        "autoencoder_model.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "autoencoder(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (2): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQvZgwUbsFEn",
        "outputId": "712a7080-281a-4031-e560-00fdc33c7f39"
      },
      "source": [
        "optimizer = torch.optim.Adam(lr=learning_rate, params=autoencoder_model.parameters())\n",
        "mse_loss_function = nn.MSELoss()\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    cumulated_loss = 0\n",
        "\n",
        "    for model_input, labels in dataloader:\n",
        "        model_input = model_input.cuda()\n",
        "        labels = labels.cuda()\n",
        "        model_output = autoencoder_model(model_input)\n",
        "        loss = torch.sqrt(mse_loss_function(model_output, labels))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cumulated_loss += loss.item()\n",
        "        \n",
        "    if not epoch % summary_epoch_interval:\n",
        "        print(\"Epoch %d, Total loss %0.6f\" % (epoch, cumulated_loss))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Total loss 7.211551\n",
            "Epoch 20, Total loss 7.202534\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}